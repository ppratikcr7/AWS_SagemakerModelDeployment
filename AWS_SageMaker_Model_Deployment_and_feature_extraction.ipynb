{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Deployment Steps:\n",
    "\n",
    "import boto3, re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "!mkdir keras_model\n",
    "# Upload files then ls:\n",
    "!ls keras_model\n",
    "\n",
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils \n",
    "import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "# Note: This directory structure will need to be followed - see notes \n",
    "# for the next section\n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/' + model_version\n",
    "\n",
    "import shutil\n",
    "shutil.rmtree(export_dir)\n",
    "\n",
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "build = builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "loaded_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, pooling='max',input_shape=(535,400,3))\n",
    "\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": loaded_model.input}, \\\n",
    "    outputs={\"score\": loaded_model.output})\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    build.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], \\\n",
    "        signature_def_map={\"serving_default\": signature})\n",
    "    build.save()\n",
    "    \n",
    "!ls export\n",
    "!ls export/Servo\n",
    "!ls export/Servo/1/variables\n",
    "\n",
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)\n",
    "    \n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='model.tar.gz', \\\n",
    "                key_prefix='model')\n",
    "\n",
    "!touch train.py\n",
    "\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + \\\n",
    "    sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
    "    role = role,\n",
    "    framework_version = '1.12',\n",
    "    entry_point = 'train.py')\n",
    "\n",
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')\n",
    "\n",
    "#notebook instance: ml.t2.medium\n",
    "\n",
    "print(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name as per previous cell output:\n",
    "# Approach 1: load deployed model\n",
    "endpoint_name = 'sagemaker-tensorflow-2019-08-05-03-29-25-591'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(\\\n",
    "        endpoint_name, sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: predict using deployed model on AWS sagemaker:\n",
    "###feature extractor of images in database\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import datetime\n",
    "\n",
    "features_list = []\n",
    "fname=[]\n",
    "for files in os.listdir('processed_input'):\n",
    "    fname.append(files)\n",
    "    print(files)\n",
    "    img = cv2.imread('processed_input//'+files)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(400,535))\n",
    "    img = np.array(img) \n",
    "    img = img/255 \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    intermediate_prediction=predictor.predict(img)[0]\n",
    "    features_list.append(intermediate_prediction.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Saving weights with JSON architecture:\n",
    "# import tensorflow as tf\n",
    "import keras\n",
    "loaded_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, pooling='max',input_shape=(535,400,3))\n",
    "# serialize model to JSON\n",
    "model_json = loaded_model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "loaded_model.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Saving standalone H5 weight file:\n",
    "# import tensorflow as tf\n",
    "import keras\n",
    "loaded_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, pooling='max',input_shape=(535,400,3))\n",
    "loaded_model.save(\"model-standalone.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Approach 2: Load save model from disk to compare:\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.load_weights('model1.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL_Book1_Pg4.png\n",
      "CL_Book1_Pg5.png\n",
      "CL_Book1_Pg7.png\n",
      "CL_Book1_Pg6.png\n",
      "CL_Book1_Pg2.png\n",
      "CL_Book1_Pg3.png\n",
      "CL_Book1_Pg1.png\n",
      "CL_Book1_Pg0.png\n",
      "NCERT_Pg3.png\n",
      "CL_Book1_Pg14.png\n",
      "CL_Book1_Pg15.png\n",
      "NCERT_Pg2.png\n",
      "NCERT_Pg0.png\n",
      "CL_Book1_Pg17.png\n",
      "CL_Book1_Pg16.png\n",
      "NCERT_Pg1.png\n",
      "CL_Book1_Pg12.png\n",
      "CL_Book1_Pg13.png\n",
      "NCERT_Pg4.png\n",
      "CL_Book1_Pg11.png\n",
      "CL_Book1_Pg8.png\n",
      "CL_Book1_Pg9.png\n",
      "CL_Book1_Pg10.png\n"
     ]
    }
   ],
   "source": [
    "#Approach 2: Predict from model loaded from disk:\n",
    "###feature extractor of images in database\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import datetime\n",
    "\n",
    "features_list = []\n",
    "fname=[]\n",
    "for files in os.listdir('processed_input'):\n",
    "    fname.append(files)\n",
    "    print(files)\n",
    "    img = cv2.imread('processed_input//'+files)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(400,535))\n",
    "    img = np.array(img) \n",
    "    img = img/255 \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    intermediate_prediction=loaded_model.predict(img)[0]\n",
    "    features_list.append(intermediate_prediction.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  CL_Book1_Pg0.png output  CL_Book1_Pg0.png ED =  0.3874467 cosine =  0.99981725\n",
      "  complete process took 1.7 sec.\n"
     ]
    }
   ],
   "source": [
    "###feature extractor for query image and comparing it against every feature_vec in db\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "f_list = sorted(os.listdir('test'))\n",
    "start1 = datetime.datetime.now()\n",
    "\n",
    "for files in f_list:  ###list of queries(test images)\n",
    "    img = cv2.imread('test/'+files)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(400,535))\n",
    "    #img, alpha, beta = automatic_brightness_and_contrast(img)\n",
    "    img = np.array(img) \n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    x=loaded_model.predict(img)[0]\n",
    "    min = float('inf') \n",
    "    for i in range(len(features_list)): ###list of features in db\n",
    "        a = x.flatten()\n",
    "        b= features_list[i]\n",
    "        cos = dot(a, b)/(norm(a)*norm(b))\n",
    "        val = np.linalg.norm(a-b)\n",
    "        if(val<min):\n",
    "            min = val\n",
    "            can = fname[i]\n",
    "            cos_f = cos\n",
    "    print('input ',files,'output ',can,'ED = ',min,'cosine = ',cos_f)\n",
    "    end1 = datetime.datetime.now()\n",
    "print('  complete process took', round((end1-start1).total_seconds(), 2), 'sec.') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
